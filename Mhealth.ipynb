{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#printing stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                               text        class  \\\n",
      "0  302034  I made a grave mistake I donât remember the ...  non-suicide   \n",
      "1  302035  What series you like. I have watched all my fa...  non-suicide   \n",
      "2  302036  Guys I did it! I lost my virginity but it wasn...  non-suicide   \n",
      "3  302037  This guy like me or no? So, basically I have t...  non-suicide   \n",
      "4  302040  I have no hopeMy ex boyfriend cheated on me an...      suicide   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  \n",
      "0        NaN        NaN        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "mh_data=pd.read_csv('Sdata2.csv',encoding='unicode_escape')\n",
    "#printing first five lines\n",
    "print(mh_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               69\n",
      "text            107\n",
      "class           129\n",
      "Unnamed: 3    30928\n",
      "Unnamed: 4    30931\n",
      "Unnamed: 5    30932\n",
      "Unnamed: 6    30932\n",
      "Unnamed: 7    30932\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values\n",
    "print(mh_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "text          0\n",
      "class         0\n",
      "Unnamed: 3    0\n",
      "Unnamed: 4    0\n",
      "Unnamed: 5    0\n",
      "Unnamed: 6    0\n",
      "Unnamed: 7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#replacing missing values with null string\n",
    "mh_data=mh_data.fillna('')\n",
    "print(mh_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        non-suicide\n",
      "1        non-suicide\n",
      "2        non-suicide\n",
      "3        non-suicide\n",
      "4            suicide\n",
      "            ...     \n",
      "30928    non-suicide\n",
      "30929    non-suicide\n",
      "30930    non-suicide\n",
      "30931        suicide\n",
      "30932    non-suicide\n",
      "Name: class, Length: 30933, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#separating feature and target\n",
    "X=mh_data.drop(columns='class',axis=1)\n",
    "Y=mh_data['class']\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        I made a grave mistake I donât remember the ...\n",
      "1        What series you like. I have watched all my fa...\n",
      "2        Guys I did it! I lost my virginity but it wasn...\n",
      "3        This guy like me or no? So, basically I have t...\n",
      "4        I have no hopeMy ex boyfriend cheated on me an...\n",
      "                               ...                        \n",
      "30928    If you don't like rock then your not going to ...\n",
      "30929    You how you can tell i have so many friends an...\n",
      "30930    pee probably tastes like salty teaðð¦â¼ï...\n",
      "30931    The usual stuff you find hereI'm not posting t...\n",
      "30932    I still haven't beaten the first boss in Hollo...\n",
      "Name: text, Length: 30933, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(mh_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        made grave mistak rememb post know someth lgbt...\n",
      "1        seri like watch favorit seri multipl time wond...\n",
      "2        guy lost virgin cool thought pp went soft minu...\n",
      "3        guy like basic friend keep give littl hint lik...\n",
      "4        hopemi ex boyfriend cheat gave genit herp hard...\n",
      "                               ...                        \n",
      "30928    like rock go get anyth go http musictast space...\n",
      "30929    tell mani friend lone everyth depriv pre bough...\n",
      "30930    pee probabl tast like salti tea someon drank p...\n",
      "30931    usual stuff find herei post sympathi piti know...\n",
      "30932    still beaten first boss hollow knight fought t...\n",
      "Name: text, Length: 30933, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "port_stem=PorterStemmer()\n",
    "def stemming(content):\n",
    "    stemmed_content=re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content=stemmed_content.lower()\n",
    "    stemmed_content=stemmed_content.split()\n",
    "    stemmed_content=[port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content=' '.join(stemmed_content)\n",
    "    return stemmed_content\n",
    "mh_data['text']=mh_data['text'].apply(stemming)\n",
    "print(mh_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['made grave mistak rememb post know someth lgbt commun made comment tri say someth along line straight like thought gay person whatev hell want came across homophob lost know care whether peopl get exactli word well'\n",
      " 'seri like watch favorit seri multipl time wonder guy favorit netflix mabi calm mabi watch brand new netflix seri'\n",
      " 'guy lost virgin cool thought pp went soft minut fuck' ...\n",
      " 'pee probabl tast like salti tea someon drank pee confirm'\n",
      " 'usual stuff find herei post sympathi piti know far wors situat mine want get stuff seem life point everyth done life ruin quit isol everyon even famili even like tell famili would help consid psychot probabl right know sens fuck univers want think seem like univers fuck made know made fuck think know want get peopl tri help went rough patch got tough done tough life tough look around famili sinc youngest seen ridicul shit happen fuck post area first time felt like tri take life bitch know mean serious cruel joke play despis life want know would like end even fuck whenev around friend would put macho tough guy like noth hurt kept everyth bottl anyth life complain option make better good would come fail colleg probabl never get back track light call light end tunnel get smaller day'\n",
      " 'still beaten first boss hollow knight fought time alway die realli earli fight terribl game']\n",
      "['non-suicide' 'non-suicide' 'non-suicide' ... 'non-suicide' 'suicide'\n",
      " 'non-suicide']\n"
     ]
    }
   ],
   "source": [
    "#X has features and Y has labes\n",
    "X=mh_data['text'].values\n",
    "Y=mh_data['class'].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30933,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30933,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33346)\t0.16764732931605258\n",
      "  (0, 32969)\t0.20013566234915206\n",
      "  (0, 32927)\t0.16813274028133982\n",
      "  (0, 32847)\t0.12860531529127242\n",
      "  (0, 32561)\t0.07493371584028177\n",
      "  (0, 30598)\t0.09616400940755265\n",
      "  (0, 29776)\t0.11056144127731336\n",
      "  (0, 28207)\t0.18697310766669029\n",
      "  (0, 27382)\t0.22563559355654228\n",
      "  (0, 25706)\t0.10499459779454338\n",
      "  (0, 24693)\t0.15744866718336942\n",
      "  (0, 23015)\t0.12062648687212743\n",
      "  (0, 22282)\t0.11710097501358104\n",
      "  (0, 22177)\t0.09234323013754775\n",
      "  (0, 19071)\t0.19111574650662655\n",
      "  (0, 17964)\t0.25139820058018997\n",
      "  (0, 17695)\t0.14116393706275365\n",
      "  (0, 17301)\t0.1947647240016349\n",
      "  (0, 17256)\t0.07267108614971887\n",
      "  (0, 17106)\t0.27394605424338037\n",
      "  (0, 16550)\t0.16030322715683049\n",
      "  (0, 14030)\t0.2550972372929163\n",
      "  (0, 13456)\t0.16037074750533517\n",
      "  (0, 12596)\t0.2712413080802721\n",
      "  (0, 12046)\t0.07943307302901155\n",
      "  :\t:\n",
      "  (30931, 5587)\t0.052526327876709016\n",
      "  (30931, 5546)\t0.06661680997928646\n",
      "  (30931, 4323)\t0.0562801442275847\n",
      "  (30931, 3629)\t0.0887660890769362\n",
      "  (30931, 3211)\t0.08481780824092443\n",
      "  (30931, 2999)\t0.04990325273186466\n",
      "  (30931, 2367)\t0.04913960972725895\n",
      "  (30931, 1821)\t0.10930152568282914\n",
      "  (30931, 1752)\t0.09381672962382472\n",
      "  (30931, 1535)\t0.047197256890325515\n",
      "  (30932, 29949)\t0.11993230539764974\n",
      "  (30932, 29377)\t0.24243652701458282\n",
      "  (30932, 28091)\t0.15327404689263016\n",
      "  (30932, 24301)\t0.1286805402701518\n",
      "  (30932, 16531)\t0.4325065339381604\n",
      "  (30932, 13970)\t0.3553185783774267\n",
      "  (30932, 11814)\t0.2112908154464833\n",
      "  (30932, 11276)\t0.33312830933080534\n",
      "  (30932, 10851)\t0.17382632913412024\n",
      "  (30932, 10673)\t0.22495717838155796\n",
      "  (30932, 8831)\t0.26674533758072816\n",
      "  (30932, 7652)\t0.14447165150172822\n",
      "  (30932, 3610)\t0.3161373319325266\n",
      "  (30932, 2740)\t0.3461828884634764\n",
      "  (30932, 1074)\t0.1588263878150963\n"
     ]
    }
   ],
   "source": [
    "#converting textual data to numberical data\n",
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X=vectorizer.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  8,  0,  4,  5,  6,  3,  1, 10,  9,  2], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the labels values into numberics\n",
    "from sklearn import preprocessing\n",
    "label_encoder=preprocessing.LabelEncoder()\n",
    "mh_data['class']=label_encoder.fit_transform(mh_data['class'])\n",
    "mh_data['class'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
