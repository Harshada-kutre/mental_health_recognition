{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#printing stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text        class\n",
      "0  ex wife threaten suiciderec left wife good che...      suicide\n",
      "1  weird get affect compliment come someon know i...  non-suicide\n",
      "2  final almost never hear bad year ever swear fu...  non-suicide\n",
      "3                     need helpjust help im cri hard      suicide\n",
      "4  losthello name adam struggl year afraid past y...      suicide\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "mh_data=pd.read_csv('stemmed_data.csv',encoding='latin1')\n",
    "#printing first five lines\n",
    "print(mh_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "class    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values\n",
    "print(mh_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text\n",
      "0       ex wife threaten suiciderec left wife good che...\n",
      "1       weird get affect compliment come someon know i...\n",
      "2       final almost never hear bad year ever swear fu...\n",
      "3                          need helpjust help im cri hard\n",
      "4       losthello name adam struggl year afraid past y...\n",
      "...                                                   ...\n",
      "231933  like rock go get anyth go http musictast space...\n",
      "231934  tell mani friend lone everyth depriv pre bough...\n",
      "231935  pee probabl tast like salti tea someon drank p...\n",
      "231936  usual stuff find herei post sympathi piti know...\n",
      "231937  still beaten first boss hollow knight fought t...\n",
      "\n",
      "[231938 rows x 1 columns]\n",
      "0             suicide\n",
      "1         non-suicide\n",
      "2         non-suicide\n",
      "3             suicide\n",
      "4             suicide\n",
      "             ...     \n",
      "231933    non-suicide\n",
      "231934    non-suicide\n",
      "231935    non-suicide\n",
      "231936        suicide\n",
      "231937    non-suicide\n",
      "Name: class, Length: 231938, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#separating feature and target\n",
    "X=mh_data.drop(columns='class',axis=1)\n",
    "Y=mh_data['class']\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "port_stem=PorterStemmer()\n",
    "def stemming(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('\\[.*?\\]', '',text)\n",
    "    text=re.sub(\"\\\\W\",\" \",text)\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+','',text)\n",
    "    text=re.sub('<.*?>+','',text)\n",
    "    text=re.sub('[%s]'% re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('\\n','',text)\n",
    "    text=re.sub('\\w*\\d\\w*','',text)\n",
    "    text=text.split()\n",
    "    text=[port_stem.stem(word) for word in text if not word in stopwords.words('english')]\n",
    "    text=' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ex wife threaten suiciderec left wife good cheat twice lie much decid refus go back day ago began threaten suicid tirelessli spent paat day talk keep hesit want believ come back know lot peopl threaten order get way happen realli suppos handl death hand still love wife cannot deal get cheat constantli feel insecur worri today may day hope much happen'\n",
      " 'weird get affect compliment come someon know irl feel realli good internet stranger'\n",
      " 'final almost never hear bad year ever swear fuck god annoy' ...\n",
      " 'pee probabl tast like salti tea someon drank pee confirm'\n",
      " 'usual stuff find herei post sympathi piti know far wors situat mine want get stuff seem life point everyth done life ruin quit isol everyon even famili even like tell famili would help consid psychot probabl right know sens fuck univers want think seem like univers fuck made know made fuck think know want get peopl tri help went rough patch got tough done tough life tough look around famili sinc youngest seen ridicul shit happen fuck post area first time felt like tri take life bitch know mean serious cruel joke play despis life want know would like end even fuck whenev around friend would put macho tough guy like noth hurt kept everyth bottl anyth life complain option make better good would come fail colleg probabl never get back track light call light end tunnel get smaller day'\n",
      " 'still beaten first boss hollow knight fought time alway die realli earli fight terribl game']\n",
      "['suicide' 'non-suicide' 'non-suicide' ... 'non-suicide' 'suicide'\n",
      " 'non-suicide']\n"
     ]
    }
   ],
   "source": [
    "#X has features and Y has labes\n",
    "X=mh_data['text'].values\n",
    "Y=mh_data['class'].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231938,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231938,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pd.isnull(mh_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 112398)\t0.09895357395150674\n",
      "  (0, 111269)\t0.3716087958578045\n",
      "  (0, 109793)\t0.06552396841808322\n",
      "  (0, 109432)\t0.045256200696607865\n",
      "  (0, 103926)\t0.12396649741038204\n",
      "  (0, 101436)\t0.08153377262540994\n",
      "  (0, 101061)\t0.22625045269728053\n",
      "  (0, 100284)\t0.39245214292095365\n",
      "  (0, 97607)\t0.06395914856574722\n",
      "  (0, 96568)\t0.10202240543022045\n",
      "  (0, 96100)\t0.28479456905430106\n",
      "  (0, 95859)\t0.06344725210565381\n",
      "  (0, 94335)\t0.06894862099427926\n",
      "  (0, 93082)\t0.10903799861083817\n",
      "  (0, 83040)\t0.12362481441177676\n",
      "  (0, 82275)\t0.057880141832593934\n",
      "  (0, 75355)\t0.05621625270909069\n",
      "  (0, 73809)\t0.28479456905430106\n",
      "  (0, 72499)\t0.12194171017770329\n",
      "  (0, 66241)\t0.12404239882177273\n",
      "  (0, 62130)\t0.09880886360792734\n",
      "  (0, 60187)\t0.067922179848044\n",
      "  (0, 60107)\t0.07861329404309986\n",
      "  (0, 58105)\t0.10183020707510082\n",
      "  (0, 57509)\t0.08349171034752481\n",
      "  :\t:\n",
      "  (231936, 18375)\t0.05229032881931739\n",
      "  (231936, 18243)\t0.06651116273373657\n",
      "  (231936, 14405)\t0.05652634625392117\n",
      "  (231936, 12204)\t0.08825059415073287\n",
      "  (231936, 10912)\t0.08496498574202041\n",
      "  (231936, 10208)\t0.04947049379877924\n",
      "  (231936, 8188)\t0.04893813874231188\n",
      "  (231936, 6289)\t0.10916204297345143\n",
      "  (231936, 6084)\t0.09401344565227114\n",
      "  (231936, 5313)\t0.04730447864948863\n",
      "  (231937, 100710)\t0.11908742010400226\n",
      "  (231937, 98646)\t0.23955661534746417\n",
      "  (231937, 94335)\t0.15255560059972448\n",
      "  (231937, 82275)\t0.1280655025834561\n",
      "  (231937, 55774)\t0.4429428578740125\n",
      "  (231937, 46623)\t0.35095526701855556\n",
      "  (231937, 39105)\t0.21149417749736177\n",
      "  (231937, 37186)\t0.33077546397083424\n",
      "  (231937, 35920)\t0.17180900735699317\n",
      "  (231937, 35278)\t0.22308208200390897\n",
      "  (231937, 28860)\t0.2658463076031192\n",
      "  (231937, 24986)\t0.14363324872884994\n",
      "  (231937, 12145)\t0.3211374413651791\n",
      "  (231937, 9376)\t0.3412922157384344\n",
      "  (231937, 3741)\t0.1582665732959455\n"
     ]
    }
   ],
   "source": [
    "#converting textual data to numberical data\n",
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X=vectorizer.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the labels values into numberics\n",
    "from sklearn import preprocessing\n",
    "label_encoder=preprocessing.LabelEncoder()\n",
    "mh_data['class']=label_encoder.fit_transform(mh_data['class'])\n",
    "mh_data['class'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset into training and testing\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries to fit the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=100000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training logistic regression model\n",
    "model=LogisticRegression(solver='lbfgs', max_iter=100000)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating accuracy score on training data\n",
    "X_train_prediction=model.predict(X_train)\n",
    "training_data_accuracy=accuracy_score(X_train_prediction,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data  0.9408137968202641\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of the training data \",training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating accuarcy score on the testing data\n",
    "X_test_prediction=model.predict(X_test)\n",
    "testing_data_accuracy=accuracy_score(X_test_prediction,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the testing data  0.932849012675692\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of the testing data \",testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "['suicide']\n",
      "suicide\n"
     ]
    }
   ],
   "source": [
    "#Making a predictive system\n",
    "new=X_test[1800]\n",
    "prediction=model.predict(new)\n",
    "print(type(X_test))\n",
    "print(prediction)\n",
    "print(Y_test[1800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing single input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the only place I can talk about thisUsing a throwaway account because I need to get this off of my chest but Iâ€™m scared of speaking out fully as people I know irl know my reddit account.    For the last five years Iâ€™ve been slowly growing more and more sad and upset with life due to my own stupid mistakes.   I have a loving family and sure we donâ€™t always get along but I love them all to pieces.  The stupid mistakes I made haunt me to this day, no one knows about them besides me and the people involved, and that kills me. I have so many passions I want to pursue, like my singing or my art however Iâ€™m terrified that if my face gets out there one day Iâ€™ll wake up to hear everyone I love knows what I did.   I was so so fucking stupid and if I could go back I would have stopped myself. It was only five years ago I found out what I did shouldnâ€™t have happened, that I should have never done it and since then itâ€™s been creeping up on me and eating away at me.   I canâ€™t tell anyone about it who I care about and if I went to see a doctor and looked for help, Iâ€™d be scared someone would find out, Iâ€™m scared Iâ€™d break down, Iâ€™m scared Iâ€™d lose my place in college.  Iâ€™ve thought about killing myself so many times, I even tired not taking my crohns and colitis medication for a while, hoping this illness would kill me slowly, but kill me none the less, but my mother soon found the full pill boxes and injections.   It feels like a huge weight is being dropped on my head. I wasnâ€™t forced to do what I did, I was a stupid child who didnâ€™t know what they were getting into or how bad what they were doing was. I was naive and now itâ€™ll haunt me for the rest of my life, however long thatâ€™ll be anyways.   Thank you for reading this strangers of Reddit.  This is the first and only time Iâ€™ll ever get to say these words.\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X_new=pd.Series(input())\n",
    "print(type(X_new))\n",
    "X_new=X_new.apply(stemming)\n",
    "print(type(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    place talk thisus throwaway account need get c...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['place talk thisus throwaway account need get chest iâ scare speak fulli peopl know irl know reddit account last five year iâ slowli grow sad upset life due stupid mistak love famili sure donâ alway get along love piec stupid mistak made haunt day one know besid peopl involv kill mani passion want pursu like sing art howev iâ terrifi face get one day iâ wake hear everyon love know fuck stupid could go back would stop five year ago found shouldnâ happen never done sinc itâ creep eat away canâ tell anyon care went see doctor look help iâ scare someon would find iâ scare iâ break iâ scare iâ lose place colleg iâ thought kill mani time even tire take crohn coliti medic hope ill would kill slowli kill none less mother soon found full pill box inject feel like huge weight drop head wasnâ forc stupid child didnâ know get bad naiv itâ haunt rest life howev long thatâ anyway thank read stranger reddit first time iâ ever get say word']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new=X_new.values\n",
    "print(X_new)\n",
    "type(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_new.shape)\n",
    "print(type(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 124)\t0.09901475429766744\n",
      "  (0, 123)\t0.14852213144650114\n",
      "  (0, 122)\t0.04950737714883372\n",
      "  (0, 121)\t0.04950737714883372\n",
      "  (0, 120)\t0.04950737714883372\n",
      "  (0, 119)\t0.04950737714883372\n",
      "  (0, 118)\t0.04950737714883372\n",
      "  (0, 117)\t0.04950737714883372\n",
      "  (0, 116)\t0.04950737714883372\n",
      "  (0, 115)\t0.04950737714883372\n",
      "  (0, 114)\t0.09901475429766744\n",
      "  (0, 113)\t0.04950737714883372\n",
      "  (0, 112)\t0.04950737714883372\n",
      "  (0, 111)\t0.04950737714883372\n",
      "  (0, 110)\t0.04950737714883372\n",
      "  (0, 109)\t0.04950737714883372\n",
      "  (0, 108)\t0.04950737714883372\n",
      "  (0, 107)\t0.04950737714883372\n",
      "  (0, 106)\t0.04950737714883372\n",
      "  (0, 105)\t0.04950737714883372\n",
      "  (0, 104)\t0.04950737714883372\n",
      "  (0, 103)\t0.19802950859533489\n",
      "  (0, 102)\t0.04950737714883372\n",
      "  (0, 101)\t0.04950737714883372\n",
      "  (0, 100)\t0.04950737714883372\n",
      "  :\t:\n",
      "  (0, 24)\t0.04950737714883372\n",
      "  (0, 23)\t0.04950737714883372\n",
      "  (0, 22)\t0.09901475429766744\n",
      "  (0, 21)\t0.04950737714883372\n",
      "  (0, 20)\t0.04950737714883372\n",
      "  (0, 19)\t0.04950737714883372\n",
      "  (0, 18)\t0.04950737714883372\n",
      "  (0, 17)\t0.04950737714883372\n",
      "  (0, 16)\t0.04950737714883372\n",
      "  (0, 15)\t0.04950737714883372\n",
      "  (0, 14)\t0.04950737714883372\n",
      "  (0, 13)\t0.04950737714883372\n",
      "  (0, 12)\t0.04950737714883372\n",
      "  (0, 11)\t0.04950737714883372\n",
      "  (0, 10)\t0.04950737714883372\n",
      "  (0, 9)\t0.04950737714883372\n",
      "  (0, 8)\t0.04950737714883372\n",
      "  (0, 7)\t0.04950737714883372\n",
      "  (0, 6)\t0.04950737714883372\n",
      "  (0, 5)\t0.04950737714883372\n",
      "  (0, 4)\t0.04950737714883372\n",
      "  (0, 3)\t0.04950737714883372\n",
      "  (0, 2)\t0.04950737714883372\n",
      "  (0, 1)\t0.04950737714883372\n",
      "  (0, 0)\t0.09901475429766744\n"
     ]
    }
   ],
   "source": [
    "#converting textual data to numberical data\n",
    "vect=TfidfVectorizer()\n",
    "vect.fit(X_new)\n",
    "X_new=vect.transform(X_new)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "X_new=csr_matrix(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 125)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46388, 116181)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 33 features per sample; expecting 116181",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-5bc9a993882f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 33 features per sample; expecting 116181"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(X_new)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non-suicide']\n",
      "(1, 116181) (231938, 116181)\n"
     ]
    }
   ],
   "source": [
    "csr_matrix.resize(X_new,(1,X.shape[1]))\n",
    "pred=model.predict(X_new)\n",
    "print(pred)\n",
    "print(X_new.shape,X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello sad\n",
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features per sample; expecting 116181",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-93634befa128>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features per sample; expecting 116181"
     ]
    }
   ],
   "source": [
    "X_new=\"hello its sad\"\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X_new=stemming(X_new)\n",
    "print(X_new)\n",
    "print(type(X_new))\n",
    "\n",
    "X_new=np.array(X_new).reshape(-1, 1)\n",
    "print(type(X_new))\n",
    "\n",
    "prediction=model.predict(X_new)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
