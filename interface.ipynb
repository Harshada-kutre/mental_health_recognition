{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "10\n",
      "recording complete\n",
      "Error: \n",
      "audio-chunks\\chunk2.wav : Need help remembering and name of an old toy and member when i was younger bad in 2012. \n",
      "\n",
      "audio-chunks\\chunk3.wav : Remember that kids around me use plastic ball to the magnet on the bottom. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing libraries for voice recorder\n",
    "from re import X\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import threading\n",
    "from numpy import imag\n",
    "import pyaudio\n",
    "from tkinter import SUNKEN, Button, Frame, PhotoImage,Label\n",
    "from PIL import Image, ImageTk\n",
    "import wave\n",
    "\n",
    "#importing libraries for speech to text conversion\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import speech_recognition as sr\n",
    "\n",
    "#importing libraries for gif\n",
    "from itertools import count\n",
    "\n",
    "#importing libraries to load model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "# Load the model from the file\n",
    "obj = joblib.load('saved_model.pkl')\n",
    "model=obj[0]\n",
    "vectorizer=obj[1]\n",
    "#mh_data=pd.read_csv('stemmed_data.csv')\n",
    "#X=mh_data['text'].values\n",
    "#Y=mh_data['class'].values\n",
    "#vectorizer=TfidfVectorizer()\n",
    "#vectorizer.fit(X)\n",
    "\n",
    "#recording audio on interface\n",
    "class App():\n",
    "    chunk = 1024 \n",
    "    sample_format = pyaudio.paInt16 \n",
    "    channels = 2\n",
    "    fs = 44100  \n",
    "    \n",
    "    frames = []  \n",
    "    images_list=[]\n",
    "    gif_duration=0\n",
    "    xy=0\n",
    "    global pred\n",
    "    \n",
    "    def extract_images(self,path):\n",
    "        global gif_duration\n",
    "        image=Image.open(path)\n",
    "        for r in count(1):\n",
    "            try:\n",
    "                self.images_list.append(image.copy())\n",
    "                image.seek(r)\n",
    "            except Exception as e:\n",
    "                break\n",
    "        print(len(self.images_list))\n",
    "        gif_duration=int(image.info['duration'])\n",
    "\n",
    "    def play_gif(self):\n",
    "        global xy,cur_img\n",
    "        try:\n",
    "            xy+=1\n",
    "            resize_img=self.images_list[xy].resize(\n",
    "                (900,200),Image.ANTIALIAS\n",
    "            )\n",
    "            cur_img=ImageTk.PhotoImage(resize_img)\n",
    "            self.gif_lb.configure(image=cur_img)\n",
    "            main.after(gif_duration,self.play_gif)\n",
    "        except Exception as e:\n",
    "            xy=0\n",
    "            main.after(gif_duration,self.play_gif)\n",
    "        \n",
    "\n",
    "    def __init__(self, master):\n",
    "        self.isrecording = False\n",
    "        self.button1 = tk.Button(main,font=\"arial 12 bold\",text=\"RECORD\",bg=\"#7ED9ED\",activebackground=\"blue\",command=self.startrecording).place(x=300,y=280)\n",
    "        self.button2 = tk.Button(main,font=\"arial 12 bold\",text=\"STOP\",bg=\"#7ED9ED\",activebackground=\"blue\",command=self.stoprecording).place(x=450,y=280)\n",
    "        self.gif_lb=tk.Label(main)\n",
    "        self.gif_lb.place(x=0,y=50)\n",
    "\n",
    "    def startrecording(self):\n",
    "        global xy\n",
    "        xy=0\n",
    "        self.p = pyaudio.PyAudio()  \n",
    "        self.stream = self.p.open(format=self.sample_format,channels=self.channels,rate=self.fs,frames_per_buffer=self.chunk,input=True)\n",
    "        self.isrecording = True\n",
    "        \n",
    "        print('Recording')\n",
    "        t = threading.Thread(target=self.record)\n",
    "        t.start()\n",
    "        \n",
    "        self.extract_images(\"sound_wave.gif\")\n",
    "        self.play_gif()\n",
    "\n",
    "        self.label3=tk.Label(main,text=\"RECORDING AUDIO...\",font=\"arial 10 bold\",fg=\"red\").place(x=300,y=315)\n",
    "\n",
    "    def stoprecording(self):\n",
    "        #stemming\n",
    "        port_stem=PorterStemmer()\n",
    "        def stemming(content):\n",
    "            stemmed_content=re.sub('[^a-zA-Z]',' ',content)\n",
    "            stemmed_content=stemmed_content.lower()\n",
    "            stemmed_content=stemmed_content.split()\n",
    "            stemmed_content=[port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "            stemmed_content=' '.join(stemmed_content)\n",
    "            return stemmed_content\n",
    "        \n",
    "        self.isrecording = False\n",
    "        print('recording complete')\n",
    "        self.filename='recording'\n",
    "        self.filename = self.filename+\".wav\"\n",
    "        wf = wave.open(self.filename, 'wb')\n",
    "        wf.setnchannels(self.channels)\n",
    "        wf.setsampwidth(self.p.get_sample_size(self.sample_format))\n",
    "        wf.setframerate(self.fs)\n",
    "        wf.writeframes(b''.join(self.frames))\n",
    "        wf.close()\n",
    "        #-------------------speech to text conversion----------------------------------------------------------\n",
    "        r=sr.Recognizer()\n",
    "        path=\"recording.wav\"\n",
    "        data=self.get_large_audio_transcription(path,r)\n",
    "        self.label=tk.Label(frame1,text=data,font=\"arial 15 bold\",fg=\"blue\",bg=\"#7ED9ED\").place(x=5,y=5)\n",
    "        self.gif_lb.destroy()\n",
    "        self.label3=tk.Label(main,text=\"RECORDING COMPLETE\",font=\"arial 10 bold\",fg=\"green\").place(x=300,y=315)\n",
    "        #-------------------detection---------------------------------------------------------------------------\n",
    "        data=pd.Series(data)\n",
    "        data=data.apply(stemming)\n",
    "        data=data.values\n",
    "        #vect=TfidfVectorizer()\n",
    "        #vect.fit(data)\n",
    "        data=vectorizer.transform(data)\n",
    "        data=csr_matrix(data)\n",
    "        #csr_matrix.resize(data,(1,116181))\n",
    "        pred=model.predict(data)\n",
    "        messagebox.showinfo(\"Predicted result\",pred)\n",
    "        #self.button3 = tk.Button(main,font=\"arial 12 bold\",text=\"PREDICT RESULT\",bg=\"#7ED9ED\",activebackground=\"blue\",command=self.popup).place(x=550,y=280)\n",
    "        \n",
    "    def popup(self):\n",
    "        messagebox.showinfo(\"Predicted Result\",pred)\n",
    "    \n",
    "    def get_large_audio_transcription(self,path,r):\n",
    "        sound = AudioSegment.from_wav(path)  \n",
    "        chunks = split_on_silence(sound,min_silence_len = 500,silence_thresh = sound.dBFS-14,keep_silence=500,)\n",
    "        folder_name = \"audio-chunks\"\n",
    "        if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "        whole_text = \"\"\n",
    "        for i, audio_chunk in enumerate(chunks, start=1):\n",
    "            chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "            audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "            with sr.AudioFile(chunk_filename) as source:\n",
    "                audio_listened = r.record(source)\n",
    "                try:\n",
    "                    text = r.recognize_google(audio_listened)\n",
    "                except sr.UnknownValueError as e:\n",
    "                    print(\"Error:\", str(e))\n",
    "                else:\n",
    "                    text = f\"{text.capitalize()}. \"+\"\\n\"\n",
    "                    print(chunk_filename, \":\", text)\n",
    "                    whole_text += text\n",
    "        return whole_text\n",
    "\n",
    "    def record(self):\n",
    "       \n",
    "        while self.isrecording:\n",
    "            data = self.stream.read(self.chunk)\n",
    "            self.frames.append(data)\n",
    "\t\t\n",
    "main=tk.Tk()\n",
    "main.title(\"Suicidal Thoughts Detection in Mentally Disturbed person (ML)\")\n",
    "main.geometry('900x700')\n",
    "main.resizable(False,False)\n",
    "\n",
    "#icon\n",
    "#main.iconphoto(False,PhotoImage(file=\"logo.png\"))\n",
    "\n",
    "#LAbel 1\n",
    "fl=Label(main,text=\"speak out your mind\",relief=\"ridge\" ,font=\"arial 15 bold\",bg=\"blue\",fg=\"white\").place(x=300,y=5)\n",
    "#Label 2\n",
    "names=tk.Label(main,font=\"arial 12 bold\",text=\"Made By- Harshada, Samrudhhi, Vrushali, Srushti\",fg=\"blue\").place(x=260,y=670)\n",
    "\n",
    "\n",
    "#Recorder image\n",
    "image=Image.open(\"wavelength.png\")\n",
    "resize_image=image.resize((900,200))\n",
    "img=ImageTk.PhotoImage(resize_image)\n",
    "label2=Label(image=img)\n",
    "label2.image=img\n",
    "label2.place(x=0,y=50)\n",
    "\n",
    "#Creating frames\n",
    "frame1=Frame(main,width=890,height=300,bg=\"#7ED9ED\",bd=5,relief=SUNKEN)\n",
    "frame1.place(x=5,y=350)\n",
    "\n",
    "app = App(main)\n",
    "main.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
